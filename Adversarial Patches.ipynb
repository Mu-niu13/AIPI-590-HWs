{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mu-niu13/AIPI-590-HWs/blob/main/Adversarial%20Patches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu6zl_sShXHm"
      },
      "source": [
        "# AIPI 590 - XAI | Adversarial Patches\n",
        "\n",
        "### Mu Niu\n",
        "\n",
        "The below code chunks were generated using Claude 4.5 Sonnet on 11/2/2025 at 9:32pm.\n",
        "\n",
        "https://claude.ai/public/artifacts/ff28fbfa-7b4d-4ab9-a79d-97922c58e7ef\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Libs"
      ],
      "metadata": {
        "id": "GmN_XQNg4nMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "except:\n",
        "    from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError:\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "thDWEZHOhru_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"../data\"\n",
        "CHECKPOINT_PATH = \"../saved_models/tutorial10\"\n",
        "\n",
        "# Seed\n",
        "pl.seed_everything(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "qhIj2O0tktM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download Data and Load Pre-Trained Model"
      ],
      "metadata": {
        "id": "ePHszwaMk3Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(DATASET_PATH, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# Download dataset\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
        "pretrained_files = [(DATASET_PATH, \"TinyImageNet.zip\")]\n",
        "\n",
        "for dir_name, file_name in pretrained_files:\n",
        "    file_path = os.path.join(dir_name, file_name)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "            if file_name.endswith(\".zip\"):\n",
        "                print(\"Unzipping...\")\n",
        "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(file_path.rsplit(\"/\", 1)[0])\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "# Load model\n",
        "os.environ[\"TORCH_HOME\"] = CHECKPOINT_PATH\n",
        "pretrained_model = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
        "pretrained_model = pretrained_model.to(device)\n",
        "pretrained_model.eval()\n",
        "\n",
        "for p in pretrained_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "print(\"Model loaded\")\n",
        "\n",
        "# Setup dataset\n",
        "NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
        "NORM_STD = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "plain_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)\n",
        "])\n",
        "\n",
        "imagenet_path = os.path.join(DATASET_PATH, \"TinyImageNet/\")\n",
        "dataset = torchvision.datasets.ImageFolder(root=imagenet_path, transform=plain_transforms)\n",
        "data_loader = data.DataLoader(dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=4)\n",
        "\n",
        "with open(os.path.join(imagenet_path, \"label_list.json\"), \"r\") as f:\n",
        "    label_names = json.load(f)\n",
        "\n",
        "print(f\"Dataset loaded: {len(dataset)} images\")"
      ],
      "metadata": {
        "id": "LImOYSjGkzIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adversarial Patch Function"
      ],
      "metadata": {
        "id": "Vb0C58gylPfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR_MEANS = torch.FloatTensor(NORM_MEAN)[:, None, None]\n",
        "TENSOR_STD = torch.FloatTensor(NORM_STD)[:, None, None]\n",
        "\n",
        "def patch_forward(patch):\n",
        "    \"\"\"Map patch parameters to image space.\"\"\"\n",
        "    return (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)\n",
        "\n",
        "def place_patch(img, patch):\n",
        "    \"\"\"Place patch at random location in images.\"\"\"\n",
        "    img_copy = img.clone()\n",
        "    for i in range(img_copy.shape[0]):\n",
        "        # Random placement\n",
        "        h_offset = np.random.randint(0, img_copy.shape[2] - patch.shape[1] - 1)\n",
        "        w_offset = np.random.randint(0, img_copy.shape[3] - patch.shape[2] - 1)\n",
        "        img_copy[i, :, h_offset:h_offset+patch.shape[1],\n",
        "                 w_offset:w_offset+patch.shape[2]] = patch_forward(patch)\n",
        "    return img_copy\n",
        "\n",
        "def train_optimal_patch(model, target_class, patch_size=64, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Train OPTIMAL adversarial patch with extended training for best performance.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING OPTIMAL PERFORMANCE PATCH\")\n",
        "    print(f\"Target: {label_names[target_class]}\")\n",
        "    print(f\"Patch size: {patch_size}x{patch_size}\")\n",
        "    print(f\"Training epochs: {num_epochs} (extended for best performance)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Split dataset\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [4500, 500])\n",
        "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True,\n",
        "                                   drop_last=True, num_workers=4)\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False,\n",
        "                                drop_last=False, num_workers=4)\n",
        "\n",
        "    # Initialize patch with random noise\n",
        "    patch = nn.Parameter(torch.randn(3, patch_size, patch_size) * 0.1, requires_grad=True)\n",
        "\n",
        "    # Optimizer with learning rate schedule\n",
        "    optimizer = torch.optim.SGD([patch], lr=0.1, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                           factor=0.5, patience=2)\n",
        "    loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    val_accs = []\n",
        "    best_patch = None\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "\n",
        "        # Progress bar with fallback\n",
        "        try:\n",
        "            t = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "        except:\n",
        "            t = train_loader\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "\n",
        "        batch_count = 0\n",
        "        for img, _ in t:\n",
        "            # Place patch\n",
        "            img_patched = place_patch(img, patch)\n",
        "            img_patched = img_patched.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            pred = model(img_patched)\n",
        "\n",
        "            # Target labels\n",
        "            labels = torch.zeros(img_patched.shape[0], device=device,\n",
        "                               dtype=torch.long).fill_(target_class)\n",
        "\n",
        "            # Loss\n",
        "            loss = loss_module(pred, labels)\n",
        "\n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "            # Update progress bar if available\n",
        "            try:\n",
        "                t.set_postfix({'loss': f'{loss.item():.3f}'})\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            batch_count += 1\n",
        "            if batch_count % 20 == 0:\n",
        "                print(f\"  Batch {batch_count}: loss={loss.item():.3f}\", end='\\r')\n",
        "\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "        train_losses.append(avg_loss)\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        # Validation every epoch\n",
        "        acc, top5 = eval_patch_quick(model, patch, val_loader, target_class, num_batches=10)\n",
        "        val_accs.append(acc.item())\n",
        "\n",
        "        print(f\"Epoch {epoch+1:2d}: Loss={avg_loss:.4f} | Top-1={100*acc:.1f}% | Top-5={100*top5:.1f}%\")\n",
        "\n",
        "        # Save best patch\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_patch = patch.data.clone()\n",
        "            print(f\"           ‚≠ê New best! Saving checkpoint...\")\n",
        "\n",
        "    # Use best patch\n",
        "    if best_patch is not None:\n",
        "        patch.data = best_patch\n",
        "\n",
        "    # Final full evaluation\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"FINAL EVALUATION ON FULL VALIDATION SET\")\n",
        "    print(\"-\"*70)\n",
        "    acc, top5 = eval_patch_full(model, patch, val_loader, target_class)\n",
        "\n",
        "    # Plot training curves\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    ax1.plot(train_losses, linewidth=2)\n",
        "    ax1.set_xlabel('Epoch', fontweight='bold')\n",
        "    ax1.set_ylabel('Training Loss', fontweight='bold')\n",
        "    ax1.set_title('Training Loss Curve', fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    ax2.plot(val_accs, linewidth=2, label='Top-1 Accuracy')\n",
        "    ax2.axhline(y=best_acc.item(), color='r', linestyle='--', label=f'Best: {100*best_acc:.1f}%')\n",
        "    ax2.set_xlabel('Epoch', fontweight='bold')\n",
        "    ax2.set_ylabel('Validation Accuracy', fontweight='bold')\n",
        "    ax2.set_title('Validation Accuracy Curve', fontweight='bold')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_ylim([0, 1])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    results = {\n",
        "        \"acc\": acc.item(),\n",
        "        \"top5\": top5.item(),\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_accs\": val_accs,\n",
        "        \"best_acc\": best_acc.item()\n",
        "    }\n",
        "\n",
        "    print(f\"\\n‚úì Training Complete!\")\n",
        "    print(f\"  Final Top-1 Success Rate: {100*acc:.2f}%\")\n",
        "    print(f\"  Final Top-5 Success Rate: {100*top5:.2f}%\")\n",
        "\n",
        "    return patch.data, results\n",
        "\n",
        "def eval_patch_quick(model, patch, val_loader, target_class, num_batches=10):\n",
        "    \"\"\"Quick evaluation on subset of data.\"\"\"\n",
        "    model.eval()\n",
        "    tp, tp_5, counter = 0., 0., 0.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (img, img_labels) in enumerate(val_loader):\n",
        "            if batch_idx >= num_batches:\n",
        "                break\n",
        "\n",
        "            # Apply patch twice for stability\n",
        "            for _ in range(2):\n",
        "                patch_img = place_patch(img, patch)\n",
        "                patch_img = patch_img.to(device)\n",
        "                img_labels = img_labels.to(device)\n",
        "\n",
        "                pred = model(patch_img)\n",
        "\n",
        "                # Exclude images that are already target class\n",
        "                mask = img_labels != target_class\n",
        "                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, mask).sum()\n",
        "                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), mask).sum()\n",
        "                counter += mask.sum()\n",
        "\n",
        "    return tp/counter if counter > 0 else 0, tp_5/counter if counter > 0 else 0\n",
        "\n",
        "def eval_patch_full(model, patch, val_loader, target_class):\n",
        "    \"\"\"Full evaluation on entire validation set.\"\"\"\n",
        "    model.eval()\n",
        "    tp, tp_5, counter = 0., 0., 0.\n",
        "\n",
        "    print(\"Running full evaluation...\")\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            iterator = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
        "        except:\n",
        "            iterator = val_loader\n",
        "            print(\"Evaluating batches...\")\n",
        "\n",
        "        batch_count = 0\n",
        "        for img, img_labels in iterator:\n",
        "            # Test at multiple positions\n",
        "            for _ in range(4):\n",
        "                patch_img = place_patch(img, patch)\n",
        "                patch_img = patch_img.to(device)\n",
        "                img_labels = img_labels.to(device)\n",
        "\n",
        "                pred = model(patch_img)\n",
        "\n",
        "                mask = img_labels != target_class\n",
        "                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, mask).sum()\n",
        "                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), mask).sum()\n",
        "                counter += mask.sum()\n",
        "\n",
        "            batch_count += 1\n",
        "            if batch_count % 5 == 0:\n",
        "                current_acc = (tp/counter).item() if counter > 0 else 0\n",
        "                print(f\"  Processed {batch_count} batches, current acc: {100*current_acc:.1f}%\", end='\\r')\n",
        "\n",
        "    print()  # New line after progress\n",
        "    return tp/counter, tp_5/counter"
      ],
      "metadata": {
        "id": "-Ae2C6fZlLzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creative Styling"
      ],
      "metadata": {
        "id": "kpUkiQIpz_P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import qrcode\n",
        "except ModuleNotFoundError:\n",
        "    !pip install qrcode[pil]\n",
        "    import qrcode\n",
        "\n",
        "def create_qr_code_mask(size=64, message=\"AI Security Research\"):\n",
        "    \"\"\"Create QR code pattern to use as styling mask.\"\"\"\n",
        "    qr = qrcode.QRCode(\n",
        "        version=1,\n",
        "        error_correction=qrcode.constants.ERROR_CORRECT_L,\n",
        "        box_size=10,\n",
        "        border=1,\n",
        "    )\n",
        "    qr.add_data(message)\n",
        "    qr.make(fit=True)\n",
        "\n",
        "    qr_img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n",
        "    qr_img = qr_img.resize((size, size), Image.LANCZOS)\n",
        "    qr_array = np.array(qr_img.convert('RGB')).astype(np.float32) / 255.0\n",
        "    qr_tensor = torch.from_numpy(qr_array).permute(2, 0, 1)\n",
        "\n",
        "    return qr_tensor\n",
        "\n",
        "def style_as_qr_code(patch, qr_blend=0.25):\n",
        "    \"\"\"Style patch to look like QR code.\"\"\"\n",
        "    qr_template = create_qr_code_mask(size=patch.shape[1])\n",
        "\n",
        "    patch_display = torch.tanh(patch)\n",
        "    qr_display = 2 * qr_template - 1\n",
        "\n",
        "    styled = patch_display + qr_blend * (qr_display - patch_display)\n",
        "    styled_patch = torch.atanh(torch.clamp(styled, -0.999, 0.999))\n",
        "\n",
        "    return styled_patch\n",
        "\n",
        "def style_as_barcode(patch, stripe_width=3):\n",
        "    \"\"\"Style patch to look like a barcode.\"\"\"\n",
        "    patch_vis = torch.tanh(patch)\n",
        "\n",
        "    # Create vertical stripe pattern\n",
        "    stripes = torch.zeros_like(patch_vis[0])\n",
        "    for i in range(0, patch_vis.shape[2], stripe_width * 2):\n",
        "        stripes[:, i:i+stripe_width] = 1.0\n",
        "\n",
        "    # Apply stripes\n",
        "    blend_factor = 0.3\n",
        "    for c in range(3):\n",
        "        styled = patch_vis[c] + blend_factor * (2 * stripes - 1 - patch_vis[c])\n",
        "        patch_vis[c] = styled\n",
        "\n",
        "    styled_patch = torch.atanh(torch.clamp(patch_vis, -0.999, 0.999))\n",
        "    return styled_patch\n",
        "\n",
        "def add_border(patch, border_width=2, border_color='white'):\n",
        "    \"\"\"Add a clean border around the patch.\"\"\"\n",
        "    patch_vis = torch.tanh(patch)\n",
        "\n",
        "    if border_color == 'black':\n",
        "        color_val = -1.0\n",
        "    elif border_color == 'white':\n",
        "        color_val = 1.0\n",
        "    else:\n",
        "        color_val = 0.0\n",
        "\n",
        "    patch_vis[:, :border_width, :] = color_val\n",
        "    patch_vis[:, -border_width:, :] = color_val\n",
        "    patch_vis[:, :, :border_width] = color_val\n",
        "    patch_vis[:, :, -border_width:] = color_val\n",
        "\n",
        "    styled_patch = torch.atanh(torch.clamp(patch_vis, -0.999, 0.999))\n",
        "    return styled_patch\n",
        "\n",
        "def compare_creative_styles(original_patch, target_class):\n",
        "    \"\"\"\n",
        "    Test different creative styling options (QR codes and barcodes)\n",
        "    and compare their effectiveness.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATIVE STYLING COMPARISON: QR CODES & BARCODES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create styled versions with different parameters\n",
        "    styles = {\n",
        "        'Original (No Styling)': original_patch,\n",
        "        'QR Code (Light 15%)': style_as_qr_code(original_patch, qr_blend=0.15),\n",
        "        'QR Code (Medium 25%)': style_as_qr_code(original_patch, qr_blend=0.25),\n",
        "        'QR Code (Strong 35%)': style_as_qr_code(original_patch, qr_blend=0.35),\n",
        "        'Barcode (Thin Lines)': style_as_barcode(original_patch, stripe_width=2),\n",
        "        'Barcode (Medium Lines)': style_as_barcode(original_patch, stripe_width=3),\n",
        "        'Barcode (Thick Lines)': style_as_barcode(original_patch, stripe_width=4),\n",
        "    }\n",
        "\n",
        "    # Test each style\n",
        "    val_set = torch.utils.data.random_split(dataset, [4500, 500])[1]\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False,\n",
        "                                 drop_last=False, num_workers=4)\n",
        "\n",
        "    results = {}\n",
        "    print(\"\\nTesting styled patches (this may take a moment)...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for style_name, styled_patch in styles.items():\n",
        "        acc, top5 = eval_patch_quick(pretrained_model, styled_patch,\n",
        "                                     val_loader, target_class, num_batches=15)\n",
        "        results[style_name] = {'acc': acc.item(), 'top5': top5.item()}\n",
        "        print(f\"{style_name:30s} ‚Üí Top-1: {100*acc:5.1f}%  Top-5: {100*top5:5.1f}%\")\n",
        "\n",
        "    # Visualize all styles\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUAL COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, (style_name, styled_patch) in enumerate(styles.items()):\n",
        "        if idx >= len(axes):\n",
        "            break\n",
        "\n",
        "        patch_vis = (torch.tanh(styled_patch) + 1) / 2\n",
        "        patch_vis = patch_vis.cpu().permute(1, 2, 0).numpy()\n",
        "        patch_vis = np.clip(patch_vis, 0, 1)\n",
        "\n",
        "        axes[idx].imshow(patch_vis)\n",
        "        acc = results[style_name]['acc']\n",
        "        top5 = results[style_name]['top5']\n",
        "        axes[idx].set_title(f\"{style_name}\\nTop-1: {100*acc:.1f}% | Top-5: {100*top5:.1f}%\",\n",
        "                           fontweight='bold', fontsize=10)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for idx in range(len(styles), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Creative Style Comparison - Target: {label_names[target_class]}\",\n",
        "                 fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Performance comparison chart\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PERFORMANCE ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    # Bar chart\n",
        "    style_names = list(results.keys())\n",
        "    top1_accs = [results[s]['acc'] * 100 for s in style_names]\n",
        "    top5_accs = [results[s]['top5'] * 100 for s in style_names]\n",
        "\n",
        "    x = np.arange(len(style_names))\n",
        "    width = 0.35\n",
        "\n",
        "    bars1 = ax1.bar(x - width/2, top1_accs, width, label='Top-1', alpha=0.8)\n",
        "    bars2 = ax1.bar(x + width/2, top5_accs, width, label='Top-5', alpha=0.8)\n",
        "\n",
        "    ax1.set_xlabel('Style', fontweight='bold')\n",
        "    ax1.set_ylabel('Success Rate (%)', fontweight='bold')\n",
        "    ax1.set_title('Performance Comparison', fontweight='bold')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(style_names, rotation=45, ha='right')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3, axis='y')\n",
        "    ax1.set_ylim([0, 100])\n",
        "\n",
        "    # Performance drop from original\n",
        "    original_acc = results['Original (No Styling)']['acc']\n",
        "    drops = [(original_acc - results[s]['acc']) * 100 for s in style_names[1:]]\n",
        "\n",
        "    colors = ['green' if d < 5 else 'orange' if d < 10 else 'red' for d in drops]\n",
        "    ax2.barh(style_names[1:], drops, color=colors, alpha=0.7)\n",
        "    ax2.set_xlabel('Performance Drop (%)', fontweight='bold')\n",
        "    ax2.set_title('Performance Loss from Original', fontweight='bold')\n",
        "    ax2.axvline(x=5, color='green', linestyle='--', alpha=0.5, label='<5% (Excellent)')\n",
        "    ax2.axvline(x=10, color='orange', linestyle='--', alpha=0.5, label='<10% (Good)')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Recommendations\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RECOMMENDATIONS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    best_overall = max(results.items(), key=lambda x: x[1]['acc'])\n",
        "    print(f\"\\n‚úì Best Overall Performance: {best_overall[0]}\")\n",
        "    print(f\"  Success rate: {100*best_overall[1]['acc']:.1f}%\")\n",
        "\n",
        "    # Best QR code\n",
        "    qr_styles = {k: v for k, v in results.items() if 'QR Code' in k}\n",
        "    best_qr = max(qr_styles.items(), key=lambda x: x[1]['acc'])\n",
        "    qr_drop = (original_acc - best_qr[1]['acc']) * 100\n",
        "    print(f\"\\n‚úì Best QR Code Style: {best_qr[0]}\")\n",
        "    print(f\"  Success rate: {100*best_qr[1]['acc']:.1f}%\")\n",
        "    print(f\"  Performance drop: {qr_drop:.1f}%\")\n",
        "    if qr_drop < 5:\n",
        "        print(f\"  ‚Üí EXCELLENT! Minimal performance loss\")\n",
        "    elif qr_drop < 10:\n",
        "        print(f\"  ‚Üí GOOD! Acceptable performance trade-off\")\n",
        "    else:\n",
        "        print(f\"  ‚Üí Consider lighter styling\")\n",
        "\n",
        "    # Best Barcode\n",
        "    barcode_styles = {k: v for k, v in results.items() if 'Barcode' in k}\n",
        "    best_barcode = max(barcode_styles.items(), key=lambda x: x[1]['acc'])\n",
        "    barcode_drop = (original_acc - best_barcode[1]['acc']) * 100\n",
        "    print(f\"\\n‚úì Best Barcode Style: {best_barcode[0]}\")\n",
        "    print(f\"  Success rate: {100*best_barcode[1]['acc']:.1f}%\")\n",
        "    print(f\"  Performance drop: {barcode_drop:.1f}%\")\n",
        "    if barcode_drop < 5:\n",
        "        print(f\"  ‚Üí EXCELLENT! Minimal performance loss\")\n",
        "    elif barcode_drop < 10:\n",
        "        print(f\"  ‚Üí GOOD! Acceptable performance trade-off\")\n",
        "    else:\n",
        "        print(f\"  ‚Üí Consider lighter styling\")\n",
        "\n",
        "    # Final recommendation\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    if best_qr[1]['acc'] > best_barcode[1]['acc']:\n",
        "        print(f\"üéØ FINAL RECOMMENDATION: Use {best_qr[0]}\")\n",
        "        print(f\"   Offers best balance of creativity and effectiveness!\")\n",
        "        return best_qr[0], styles[best_qr[0]]\n",
        "    else:\n",
        "        print(f\"üéØ FINAL RECOMMENDATION: Use {best_barcode[0]}\")\n",
        "        print(f\"   Offers best balance of creativity and effectiveness!\")\n",
        "        return best_barcode[0], styles[best_barcode[0]]"
      ],
      "metadata": {
        "id": "J5OCiqJRz_E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization Function"
      ],
      "metadata": {
        "id": "4_H9vg-Elj4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_prediction(img, label, pred, K=5, adv_img=None, patch=None):\n",
        "    \"\"\"Visualize predictions.\"\"\"\n",
        "    if isinstance(img, torch.Tensor):\n",
        "        img = img.cpu().permute(1, 2, 0).numpy()\n",
        "        img = (img * NORM_STD[None, None]) + NORM_MEAN[None, None]\n",
        "        img = np.clip(img, 0, 1)\n",
        "        label = label.item()\n",
        "\n",
        "    if adv_img is not None and patch is not None:\n",
        "        fig, ax = plt.subplots(1, 4, figsize=(16, 3),\n",
        "                              gridspec_kw={'width_ratios': [1, 1, 1, 2]})\n",
        "    else:\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(10, 3),\n",
        "                              gridspec_kw={'width_ratios': [1, 2]})\n",
        "\n",
        "    # Original\n",
        "    ax[0].imshow(img)\n",
        "    ax[0].set_title(f'Original: {label_names[label]}', fontweight='bold')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    if adv_img is not None and patch is not None:\n",
        "        # Adversarial\n",
        "        adv_img = adv_img.cpu().permute(1, 2, 0).numpy()\n",
        "        adv_img = (adv_img * NORM_STD[None, None]) + NORM_MEAN[None, None]\n",
        "        adv_img = np.clip(adv_img, 0, 1)\n",
        "        ax[1].imshow(adv_img)\n",
        "        ax[1].set_title('With Patch', fontweight='bold')\n",
        "        ax[1].axis('off')\n",
        "\n",
        "        # Patch\n",
        "        patch_vis = (torch.tanh(patch) + 1) / 2\n",
        "        patch_vis = patch_vis.cpu().permute(1, 2, 0).numpy()\n",
        "        patch_vis = np.clip(patch_vis, 0, 1)\n",
        "        ax[2].imshow(patch_vis)\n",
        "        ax[2].set_title('Adversarial Patch', fontweight='bold')\n",
        "        ax[2].axis('off')\n",
        "\n",
        "    # Predictions\n",
        "    if abs(pred.sum().item() - 1.0) > 1e-4:\n",
        "        pred = torch.softmax(pred, dim=-1)\n",
        "\n",
        "    topk_vals, topk_idx = pred.topk(K, dim=-1)\n",
        "    topk_vals, topk_idx = topk_vals.cpu().numpy(), topk_idx.cpu().numpy()\n",
        "\n",
        "    colors = [\"C2\" if topk_idx[i] == label else \"C0\" for i in range(K)]\n",
        "    ax[-1].barh(np.arange(K), topk_vals * 100.0, align='center', color=colors)\n",
        "    ax[-1].set_yticks(np.arange(K))\n",
        "    ax[-1].set_yticklabels([label_names[c] for c in topk_idx])\n",
        "    ax[-1].invert_yaxis()\n",
        "    ax[-1].set_xlabel('Confidence (%)', fontweight='bold')\n",
        "    ax[-1].set_title('Top-5 Predictions', fontweight='bold')\n",
        "    ax[-1].set_xlim([0, 100])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def demonstrate_patch(patch, target_class, patch_name=\"Patch\", num_examples=6):\n",
        "    \"\"\"Show patch effectiveness on multiple images.\"\"\"\n",
        "    exmp_batch, label_batch = next(iter(data_loader))\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"DEMONSTRATION: {patch_name}\")\n",
        "    print(f\"Target: {label_names[target_class]}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Show the patch\n",
        "    patch_vis = (torch.tanh(patch) + 1) / 2\n",
        "    patch_vis = patch_vis.cpu().permute(1, 2, 0).numpy()\n",
        "    patch_vis = np.clip(patch_vis, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(patch_vis)\n",
        "    plt.title(f'{patch_name}\\nTarget: {label_names[target_class]}',\n",
        "             fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n{patch_name} Effects on Sample Images:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Show examples\n",
        "    for i in range(min(num_examples, len(exmp_batch))):\n",
        "        with torch.no_grad():\n",
        "            orig_pred = pretrained_model(exmp_batch[i:i+1].to(device))\n",
        "\n",
        "        # Create adversarial\n",
        "        adv_batch = exmp_batch[i:i+1].clone()\n",
        "        h_offset = np.random.randint(0, adv_batch.shape[2] - patch.shape[1] - 1)\n",
        "        w_offset = np.random.randint(0, adv_batch.shape[3] - patch.shape[2] - 1)\n",
        "        adv_batch[0, :, h_offset:h_offset+patch.shape[1],\n",
        "                  w_offset:w_offset+patch.shape[2]] = patch_forward(patch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            adv_pred = pretrained_model(adv_batch.to(device))\n",
        "\n",
        "        show_prediction(exmp_batch[i], label_batch[i], adv_pred[0],\n",
        "                       adv_img=adv_batch[0], patch=patch)\n",
        "\n",
        "def save_patch_for_printing(patch, target_name, filename=None, size_inches=4, dpi=300):\n",
        "    \"\"\"Save high-resolution patch for printing.\"\"\"\n",
        "    if filename is None:\n",
        "        filename = f\"{target_name.replace(' ', '_')}_patch.png\"\n",
        "\n",
        "    # Convert to image\n",
        "    patch_vis = (torch.tanh(patch) + 1) / 2\n",
        "    patch_vis = patch_vis.cpu().permute(1, 2, 0).numpy()\n",
        "    patch_vis = np.clip(patch_vis, 0, 1)\n",
        "    patch_vis = (patch_vis * 255).astype(np.uint8)\n",
        "\n",
        "    # Create PIL image\n",
        "    img = Image.fromarray(patch_vis)\n",
        "\n",
        "    # Resize to print resolution\n",
        "    size_pixels = int(size_inches * dpi)\n",
        "    img = img.resize((size_pixels, size_pixels), Image.LANCZOS)\n",
        "\n",
        "    # Save\n",
        "    img.save(filename, dpi=(dpi, dpi))\n",
        "    print(f\"\\n‚úì Patch saved: '{filename}'\")\n",
        "    print(f\"  Size: {size_inches}x{size_inches} inches at {dpi} DPI\")\n",
        "    print(f\"  Resolution: {size_pixels}x{size_pixels} pixels\")\n",
        "\n",
        "    return filename"
      ],
      "metadata": {
        "id": "1xYVMO1ilZg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main"
      ],
      "metadata": {
        "id": "7jPCQqVjlvXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution: Train optimal patch, then apply creative styling.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PERFORMANCE-FIRST ADVERSARIAL PATCH WITH CREATIVE STYLING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Target selection\n",
        "    recommended_targets = [\n",
        "        'toaster', 'website', 'comic book', 'spotlight',\n",
        "        'basketball', 'traffic light', 'iPod', 'bannister'\n",
        "    ]\n",
        "\n",
        "    print(\"\\nRecommended targets:\")\n",
        "    for i, target in enumerate(recommended_targets, 1):\n",
        "        print(f\"  {i}. {target}\")\n",
        "\n",
        "    target_name = 'toaster'  # Change as needed\n",
        "    target_class = label_names.index(target_name)\n",
        "    print(f\"\\nSelected target: '{target_name}' (class index {target_class})\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 1: Train OPTIMAL performance patch with extended epochs\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: TRAINING OPTIMAL PERFORMANCE PATCH\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nTraining with extended epochs for maximum effectiveness...\")\n",
        "\n",
        "    original_patch, train_results = train_optimal_patch(\n",
        "        model=pretrained_model,\n",
        "        target_class=target_class,\n",
        "        patch_size=64,\n",
        "        num_epochs=10  # Extended training for best performance\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚úì Optimal patch achieved: {100*train_results['acc']:.1f}% success rate\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 2: Test creative styling options (QR codes & barcodes)\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 2: TESTING CREATIVE STYLING OPTIONS\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nComparing QR code and barcode styling while maintaining performance...\")\n",
        "\n",
        "    best_style_name, best_styled_patch = compare_creative_styles(\n",
        "        original_patch, target_class\n",
        "    )\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 3: Final evaluation and comparison\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 3: FINAL EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    val_set = torch.utils.data.random_split(dataset, [4500, 500])[1]\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False,\n",
        "                                 drop_last=False, num_workers=4)\n",
        "\n",
        "    print(\"\\nEvaluating best styled patch on full validation set...\")\n",
        "    final_acc, final_top5 = eval_patch_full(pretrained_model, best_styled_patch,\n",
        "                                            val_loader, target_class)\n",
        "\n",
        "    # Create summary visualization\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Original patch\n",
        "    orig_vis = (torch.tanh(original_patch) + 1) / 2\n",
        "    orig_vis = orig_vis.cpu().permute(1, 2, 0).numpy()\n",
        "    orig_vis = np.clip(orig_vis, 0, 1)\n",
        "    axes[0].imshow(orig_vis)\n",
        "    axes[0].set_title(f'Original Patch\\nPerformance: {100*train_results[\"acc\"]:.1f}%',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Best styled patch\n",
        "    styled_vis = (torch.tanh(best_styled_patch) + 1) / 2\n",
        "    styled_vis = styled_vis.cpu().permute(1, 2, 0).numpy()\n",
        "    styled_vis = np.clip(styled_vis, 0, 1)\n",
        "    axes[1].imshow(styled_vis)\n",
        "    axes[1].set_title(f'{best_style_name}\\nPerformance: {100*final_acc:.1f}%',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Performance comparison\n",
        "    categories = ['Top-1\\nSuccess', 'Top-5\\nSuccess']\n",
        "    original_scores = [train_results['acc'] * 100, train_results['top5'] * 100]\n",
        "    styled_scores = [final_acc.item() * 100, final_top5.item() * 100]\n",
        "\n",
        "    x = np.arange(len(categories))\n",
        "    width = 0.35\n",
        "\n",
        "    bars1 = axes[2].bar(x - width/2, original_scores, width, label='Original', alpha=0.8)\n",
        "    bars2 = axes[2].bar(x + width/2, styled_scores, width, label=best_style_name, alpha=0.8)\n",
        "\n",
        "    axes[2].set_ylabel('Success Rate (%)', fontweight='bold', fontsize=12)\n",
        "    axes[2].set_title('Performance Comparison', fontweight='bold', fontsize=14)\n",
        "    axes[2].set_xticks(x)\n",
        "    axes[2].set_xticklabels(categories, fontsize=11)\n",
        "    axes[2].legend(fontsize=10)\n",
        "    axes[2].grid(True, alpha=0.3, axis='y')\n",
        "    axes[2].set_ylim([0, 100])\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            axes[2].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                        f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.suptitle(f'Final Results - Target: {label_names[target_class]}',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n‚úì Original patch: {100*train_results['acc']:.1f}% success\")\n",
        "    print(f\"‚úì Styled patch: {100*final_acc:.1f}% success\")\n",
        "    print(f\"‚úì Performance drop: {100*(train_results['acc']-final_acc):.1f}%\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 4: Demonstrate both patches on sample images\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: VISUAL DEMONSTRATIONS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nüìä Demonstrating ORIGINAL patch:\")\n",
        "    demonstrate_patch(original_patch, target_class,\n",
        "                     patch_name=\"Original Patch\", num_examples=4)\n",
        "\n",
        "    print(\"\\nüìä Demonstrating STYLED patch:\")\n",
        "    demonstrate_patch(best_styled_patch, target_class,\n",
        "                     patch_name=best_style_name, num_examples=4)\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 5: Save patches for printing\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 5: SAVING PATCHES FOR PRINTING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Save original\n",
        "    orig_filename = f\"{target_name.replace(' ', '_')}_original.png\"\n",
        "    save_patch_for_printing(original_patch, f\"{target_name} (Original)\",\n",
        "                           filename=orig_filename, size_inches=4, dpi=300)\n",
        "\n",
        "    # Save styled\n",
        "    styled_filename = f\"{target_name.replace(' ', '_')}_styled.png\"\n",
        "    save_patch_for_printing(best_styled_patch, f\"{target_name} ({best_style_name})\",\n",
        "                           filename=styled_filename, size_inches=4, dpi=300)\n",
        "\n",
        "    # Create instruction sheet\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "    # Original patch\n",
        "    axes[0, 0].imshow(orig_vis)\n",
        "    axes[0, 0].set_title('ORIGINAL PATCH', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # Styled patch\n",
        "    axes[0, 1].imshow(styled_vis)\n",
        "    axes[0, 1].set_title(f'STYLED PATCH ({best_style_name})', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    # Instructions for original\n",
        "    axes[1, 0].axis('off')\n",
        "    instructions_orig = f\"\"\"\n",
        "    ORIGINAL PATCH\n",
        "    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "    Performance: {100*train_results['acc']:.1f}%\n",
        "    Target: {target_name.upper()}\n",
        "\n",
        "    PRINTING:\n",
        "    ‚Ä¢ Size: 4\" x 4\"\n",
        "    ‚Ä¢ Paper: Glossy photo paper\n",
        "    ‚Ä¢ Quality: Highest\n",
        "    ‚Ä¢ Color printing required\n",
        "\n",
        "    TESTING:\n",
        "    ‚Ä¢ Distance: 1-3 feet\n",
        "    ‚Ä¢ Good lighting needed\n",
        "    ‚Ä¢ Test at multiple angles\n",
        "\n",
        "    File: {orig_filename}\n",
        "    \"\"\"\n",
        "    axes[1, 0].text(0.1, 0.5, instructions_orig, fontsize=10, family='monospace',\n",
        "                   verticalalignment='center')\n",
        "\n",
        "    # Instructions for styled\n",
        "    axes[1, 1].axis('off')\n",
        "    instructions_styled = f\"\"\"\n",
        "    STYLED PATCH\n",
        "    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "    Performance: {100*final_acc:.1f}%\n",
        "    Target: {target_name.upper()}\n",
        "    Style: {best_style_name}\n",
        "\n",
        "    PRINTING:\n",
        "    ‚Ä¢ Size: 4\" x 4\"\n",
        "    ‚Ä¢ Paper: Glossy photo paper\n",
        "    ‚Ä¢ Quality: Highest\n",
        "    ‚Ä¢ Color printing required\n",
        "\n",
        "    TESTING:\n",
        "    ‚Ä¢ Distance: 1-3 feet\n",
        "    ‚Ä¢ Good lighting needed\n",
        "    ‚Ä¢ Test at multiple angles\n",
        "\n",
        "    File: {styled_filename}\n",
        "    \"\"\"\n",
        "    axes[1, 1].text(0.1, 0.5, instructions_styled, fontsize=10, family='monospace',\n",
        "                   verticalalignment='center')\n",
        "\n",
        "    plt.suptitle(f'PRINTING INSTRUCTIONS - Target: {label_names[target_class]}',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    instruction_file = f\"{target_name.replace(' ', '_')}_instructions.png\"\n",
        "    plt.savefig(instruction_file, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n‚úì Instruction sheet saved: '{instruction_file}'\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # FINAL SUMMARY\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚ú® FINAL SUMMARY ‚ú®\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüéØ Target: {label_names[target_class]}\")\n",
        "    print(f\"\\nüìä ORIGINAL PATCH:\")\n",
        "    print(f\"   ‚Ä¢ Success rate: {100*train_results['acc']:.1f}%\")\n",
        "    print(f\"   ‚Ä¢ Top-5 rate: {100*train_results['top5']:.1f}%\")\n",
        "    print(f\"   ‚Ä¢ File: {orig_filename}\")\n",
        "\n",
        "    print(f\"\\nüé® STYLED PATCH ({best_style_name}):\")\n",
        "    print(f\"   ‚Ä¢ Success rate: {100*final_acc:.1f}%\")\n",
        "    print(f\"   ‚Ä¢ Top-5 rate: {100*final_top5:.1f}%\")\n",
        "    print(f\"   ‚Ä¢ Performance drop: {100*(train_results['acc']-final_acc):.1f}%\")\n",
        "    print(f\"   ‚Ä¢ File: {styled_filename}\")\n",
        "\n",
        "    performance_drop = (train_results['acc'] - final_acc.item()) * 100\n",
        "\n",
        "    if final_acc > 0.70:\n",
        "        emoji = \"üéâ\"\n",
        "        rating = \"EXCELLENT\"\n",
        "        comment = \"Outstanding performance with creative styling!\"\n",
        "    elif final_acc > 0.60:\n",
        "        emoji = \"‚úÖ\"\n",
        "        rating = \"VERY GOOD\"\n",
        "        comment = \"Great balance of creativity and effectiveness!\"\n",
        "    elif final_acc > 0.50:\n",
        "        emoji = \"üëç\"\n",
        "        rating = \"GOOD\"\n",
        "        comment = \"Acceptable performance with creative design!\"\n",
        "    else:\n",
        "        emoji = \"‚ö†Ô∏è\"\n",
        "        rating = \"MODERATE\"\n",
        "        comment = \"Consider using lighter styling or original patch.\"\n",
        "\n",
        "    print(f\"\\n{emoji} OVERALL RATING: {rating}\")\n",
        "    print(f\"   {comment}\")\n",
        "\n",
        "    if performance_drop < 5:\n",
        "        print(f\"\\nüíé Minimal performance loss (<5%) - Perfect balance achieved!\")\n",
        "    elif performance_drop < 10:\n",
        "        print(f\"\\n‚ú® Small performance trade-off (<10%) - Excellent result!\")\n",
        "    elif performance_drop < 15:\n",
        "        print(f\"\\nüëå Moderate trade-off (<15%) - Good creative option!\")\n",
        "    else:\n",
        "        print(f\"\\nüí° Consider: Original patch or lighter styling for better performance\")\n",
        "\n",
        "    print(\"\\nüìÅ Files ready for physical testing!\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return {\n",
        "        'original_patch': original_patch,\n",
        "        'styled_patch': best_styled_patch,\n",
        "        'style_name': best_style_name,\n",
        "        'original_acc': train_results['acc'],\n",
        "        'styled_acc': final_acc.item(),\n",
        "        'target_name': target_name,\n",
        "        'target_class': target_class\n",
        "    }"
      ],
      "metadata": {
        "id": "ypNtTgaklpGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = main()"
      ],
      "metadata": {
        "id": "sl08KxyJlwhj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}